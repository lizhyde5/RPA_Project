{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "label_test_template.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "B4yLzjne6Tm6",
        "NaSSY_mynUVw"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ba6563e0447044c2ba4582bd16e1e5e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4672de7af9184b409e86489d9c47681e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_58c4ccff89ff44b7969591d07f20c5a3",
              "IPY_MODEL_3f511340385646ec957d90794690dd80"
            ]
          }
        },
        "4672de7af9184b409e86489d9c47681e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "58c4ccff89ff44b7969591d07f20c5a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ec553d70b3274e498a291c173126a48b",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_58e495d72c4b4a67af6db79f9e6288d5"
          }
        },
        "3f511340385646ec957d90794690dd80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_12352b3c3cd7459f878e16eadce68f83",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:00&lt;00:00, 948B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b0ce27985d3f47b8aa7719f7942577ae"
          }
        },
        "ec553d70b3274e498a291c173126a48b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "58e495d72c4b4a67af6db79f9e6288d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "12352b3c3cd7459f878e16eadce68f83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b0ce27985d3f47b8aa7719f7942577ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "20eb5d3a68a142559af2ad823dfd5767": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c595cc533d3346208c47adcb991349de",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b958ee8654b04598944dd8df69604a65",
              "IPY_MODEL_5c266aadc85b43bd833cd1340069ca2e"
            ]
          }
        },
        "c595cc533d3346208c47adcb991349de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b958ee8654b04598944dd8df69604a65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_51d3d90a332e43d6a8993b3563bd913b",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d0b277d4986b468f9e9f2dac116b7bd2"
          }
        },
        "5c266aadc85b43bd833cd1340069ca2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_fbcc7e4dfc51478ebb7a4176a6af1202",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [00:14&lt;00:00, 31.0MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_95bc74d840774f5e8797fe651d1b32f4"
          }
        },
        "51d3d90a332e43d6a8993b3563bd913b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d0b277d4986b468f9e9f2dac116b7bd2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fbcc7e4dfc51478ebb7a4176a6af1202": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "95bc74d840774f5e8797fe651d1b32f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1754eb56df454e268e74780c3d293325": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d95e958439f44132aadcce689b4572d5",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3a2cfc056d55473a90a43851150f7ef0",
              "IPY_MODEL_4ad519bab6be43e297c803f6c9a7f986"
            ]
          }
        },
        "d95e958439f44132aadcce689b4572d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3a2cfc056d55473a90a43851150f7ef0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_fafeacc2700b44158d10a0c99f03bd71",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_45a1888bdf634ce695397d06dad2062a"
          }
        },
        "4ad519bab6be43e297c803f6c9a7f986": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ecf62f84ed24443091fb44924f4bd56e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 595kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e2090f2cb6d141af97e54bfbc9c464ca"
          }
        },
        "fafeacc2700b44158d10a0c99f03bd71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "45a1888bdf634ce695397d06dad2062a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ecf62f84ed24443091fb44924f4bd56e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e2090f2cb6d141af97e54bfbc9c464ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-Bnqn00VGfY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        },
        "outputId": "6aaeaeec-8715-45d5-80e3-8e552992fa24"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/3c/91ed8f5c4e7ef3227b4119200fc0ed4b4fd965b1f0172021c25701087825/transformers-3.0.2-py3-none-any.whl (769kB)\n",
            "\u001b[K     |████████████████████████████████| 778kB 3.5MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.8.1.rc1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/d0/30d5f8d221a0ed981a186c8eb986ce1c94e3a6e87f994eae9f4aa5250217/tokenizers-0.8.1rc1-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 15.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 38.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Collecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 41.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=0605dec23fefded9fdfcc6cc2622ec8b376ff3057fc0bd0c1aa18e958f7385ea\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, sentencepiece, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.8.1rc1 transformers-3.0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67970XzEVCAL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import transformers\n",
        "# per the setting of transformers, to use any of its NLP model\n",
        "# we need to have three things: that is BertTokenizer, BertModel, BertConfig\n",
        "from transformers import BertTokenizer, BertModel, BertConfig"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X4socdVzVEHS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2f2c93f0-cdf9-42ce-940e-5ca8f19ebf52"
      },
      "source": [
        "# first, let's see if we have GPU so that we could train our model in GPU\n",
        "# GPU is really at parallel computation\n",
        "from torch import cuda\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device('cuda')\n",
        "  print(device)\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59RK1lkXU9NH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "711b4c88-405e-491a-c0ab-af975b8f6394"
      },
      "source": [
        "# collect Google Drive to Colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o2L80RjhU9s_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115,
          "referenced_widgets": [
            "ba6563e0447044c2ba4582bd16e1e5e4",
            "4672de7af9184b409e86489d9c47681e",
            "58c4ccff89ff44b7969591d07f20c5a3",
            "3f511340385646ec957d90794690dd80",
            "ec553d70b3274e498a291c173126a48b",
            "58e495d72c4b4a67af6db79f9e6288d5",
            "12352b3c3cd7459f878e16eadce68f83",
            "b0ce27985d3f47b8aa7719f7942577ae",
            "20eb5d3a68a142559af2ad823dfd5767",
            "c595cc533d3346208c47adcb991349de",
            "b958ee8654b04598944dd8df69604a65",
            "5c266aadc85b43bd833cd1340069ca2e",
            "51d3d90a332e43d6a8993b3563bd913b",
            "d0b277d4986b468f9e9f2dac116b7bd2",
            "fbcc7e4dfc51478ebb7a4176a6af1202",
            "95bc74d840774f5e8797fe651d1b32f4"
          ]
        },
        "outputId": "d3e9a61c-f6c8-4c19-800d-2ba69178410b"
      },
      "source": [
        "# create an instance of BERT model \n",
        "# note that it takes time to download the BERT model (~ 440M)\n",
        "# BERT model is big, because it has a lot of paramters. \n",
        "model = BertModel.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ba6563e0447044c2ba4582bd16e1e5e4",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "20eb5d3a68a142559af2ad823dfd5767",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKo8Z3XUYKJ_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "1754eb56df454e268e74780c3d293325",
            "d95e958439f44132aadcce689b4572d5",
            "3a2cfc056d55473a90a43851150f7ef0",
            "4ad519bab6be43e297c803f6c9a7f986",
            "fafeacc2700b44158d10a0c99f03bd71",
            "45a1888bdf634ce695397d06dad2062a",
            "ecf62f84ed24443091fb44924f4bd56e",
            "e2090f2cb6d141af97e54bfbc9c464ca"
          ]
        },
        "outputId": "8018879b-cc18-437e-a021-c9e46e2c71c5"
      },
      "source": [
        "# creat an instance of BERT tokenizer\n",
        "# as you can tell, the tokenizer is pretty small, only 232k in size\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1754eb56df454e268e74780c3d293325",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NyhRDyuDUGwu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 983
        },
        "outputId": "1692a3d9-83c3-44be-a16e-9504867c1e23"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "url = 'https://raw.githubusercontent.com/lizhyde5/RPA_Project/master/16K_AmazonReviews.csv'\n",
        "raw_review = pd.read_csv(url)\n",
        "raw_review"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>product_title</th>\n",
              "      <th>product_category</th>\n",
              "      <th>star_rating</th>\n",
              "      <th>helpful_votes</th>\n",
              "      <th>total_votes</th>\n",
              "      <th>vine</th>\n",
              "      <th>verified_purchase</th>\n",
              "      <th>review_headline</th>\n",
              "      <th>review_body</th>\n",
              "      <th>review_date</th>\n",
              "      <th>social_connectedness</th>\n",
              "      <th>environment</th>\n",
              "      <th>self_sufficiency</th>\n",
              "      <th>transparency_authenticity</th>\n",
              "      <th>tradition</th>\n",
              "      <th>individuality</th>\n",
              "      <th>diversity_equality</th>\n",
              "      <th>privacy</th>\n",
              "      <th>status</th>\n",
              "      <th>thrift_value</th>\n",
              "      <th>innovation</th>\n",
              "      <th>fun_adventure</th>\n",
              "      <th>health</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>BOSS HUGO BOSS Men's Starfish Swim Trunk</td>\n",
              "      <td>Apparel</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>Good quality</td>\n",
              "      <td>The quality is good, fits good but I didnt pay...</td>\n",
              "      <td>6/23/2014</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Vedette Megane Firm Compression Sensual Corset...</td>\n",
              "      <td>Apparel</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>I like this bodyshaper.</td>\n",
              "      <td>This body shaper does what it says. It makes y...</td>\n",
              "      <td>9/1/2013</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Adult Stilinski 24 Beacon Hills Lacrosse 2-Sid...</td>\n",
              "      <td>Apparel</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>Nice hoodie</td>\n",
              "      <td>It looks well made. I bought it for my grandda...</td>\n",
              "      <td>8/3/2015</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Carhartt Men's Sherpa Lined Sandstone Hooded M...</td>\n",
              "      <td>Apparel</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>Size Small Means Medium</td>\n",
              "      <td>Other than the sizing that is bigger than the ...</td>\n",
              "      <td>10/2/2014</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Roxy Juniors Gallery Backpack</td>\n",
              "      <td>Apparel</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>Five Stars</td>\n",
              "      <td>Love my backpack.</td>\n",
              "      <td>9/15/2014</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1656</th>\n",
              "      <td>Virus Removal Service - Jupiter Support</td>\n",
              "      <td>Software</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>IE issue</td>\n",
              "      <td>i just got done with jupiter on i script prob ...</td>\n",
              "      <td>4/26/2014</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1657</th>\n",
              "      <td>Family Tree Maker 2011 Deluxe [Old Version]</td>\n",
              "      <td>Software</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>Y</td>\n",
              "      <td>N</td>\n",
              "      <td>Not for use on a netbook</td>\n",
              "      <td>I used this software on my netbook and it divi...</td>\n",
              "      <td>9/23/2011</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1658</th>\n",
              "      <td>Learn Italian: Fluenz Italian 1 for Mac, PC, i...</td>\n",
              "      <td>Software</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>awesome program</td>\n",
              "      <td>hi, Just want to say it what a great company! ...</td>\n",
              "      <td>4/30/2010</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1659</th>\n",
              "      <td>Kaspersky Internet Security 2009 (3 User)</td>\n",
              "      <td>Software</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>Great product</td>\n",
              "      <td>Great internet security product. I guess the b...</td>\n",
              "      <td>12/22/2008</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1660</th>\n",
              "      <td>Norton 360 2013 - 1 User / 3 PC</td>\n",
              "      <td>Software</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>Disapointing right out of the box</td>\n",
              "      <td>If you are allergic to the chocolate and you a...</td>\n",
              "      <td>9/12/2013</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1661 rows × 23 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                          product_title  ... health\n",
              "0              BOSS HUGO BOSS Men's Starfish Swim Trunk  ...      0\n",
              "1     Vedette Megane Firm Compression Sensual Corset...  ...      1\n",
              "2     Adult Stilinski 24 Beacon Hills Lacrosse 2-Sid...  ...      0\n",
              "3     Carhartt Men's Sherpa Lined Sandstone Hooded M...  ...      1\n",
              "4                         Roxy Juniors Gallery Backpack  ...      0\n",
              "...                                                 ...  ...    ...\n",
              "1656            Virus Removal Service - Jupiter Support  ...      0\n",
              "1657        Family Tree Maker 2011 Deluxe [Old Version]  ...      0\n",
              "1658  Learn Italian: Fluenz Italian 1 for Mac, PC, i...  ...      0\n",
              "1659          Kaspersky Internet Security 2009 (3 User)  ...      0\n",
              "1660                    Norton 360 2013 - 1 User / 3 PC  ...      0\n",
              "\n",
              "[1661 rows x 23 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OVLbEIyuWoWW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "e77fe3e8-531a-437b-d48a-80c96dcd1a65"
      },
      "source": [
        "raw_review.iloc[398,:]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "product_title                      Women's Combed Cotton Rib-Knit Thermal Vest\n",
              "product_category                                                       Apparel\n",
              "star_rating                                                                  1\n",
              "helpful_votes                                                                0\n",
              "total_votes                                                                  0\n",
              "vine                                                                         N\n",
              "verified_purchase                                                            Y\n",
              "review_headline                    Women's Combed Cotton Rib-Knit Thermal Vest\n",
              "review_body                  it is not like it looks in the image!<br />i d...\n",
              "review_date                                                         11/23/2012\n",
              "social_connectedness                                                         0\n",
              "environment                                                                  0\n",
              "self_sufficiency                                                             0\n",
              "transparency_authenticity                                                    0\n",
              "tradition                                                                    0\n",
              "individuality                                                                0\n",
              "diversity_equality                                                           0\n",
              "privacy                                                                      0\n",
              "status                                                                       0\n",
              "thrift_value                                                                 1\n",
              "innovation                                                                   0\n",
              "fun_adventure                                                                0\n",
              "health                                                                       0\n",
              "Name: 398, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bO_VL6_GV6gF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_review = pd.DataFrame(None)\n",
        "\n",
        "train_review[['text','label']] = raw_review[['review_body','social_connectedness']].iloc[0:1661,:]\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4F0PknWZqxf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_review = train_review.dropna()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ajQpmwt2Xfds",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "f3a36834-8c8c-4db1-e4c8-ec5ba072328a"
      },
      "source": [
        "train_review.describe()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1660.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.087349</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.282431</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             label\n",
              "count  1660.000000\n",
              "mean      0.087349\n",
              "std       0.282431\n",
              "min       0.000000\n",
              "25%       0.000000\n",
              "50%       0.000000\n",
              "75%       0.000000\n",
              "max       1.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "513Gaudcu56u",
        "colab_type": "text"
      },
      "source": [
        "# Define a Customized Dataset Class and Setup the Dataloader\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "luKm7Mh6vZi4",
        "colab": {}
      },
      "source": [
        "# first let's define some key parameters we will use later\n",
        "# note this is a relatively large number, making the training process slow, \n",
        "# but it's necessary becuase a lot of reviews are long.\n",
        "max_length = 128\n",
        "# how many raw inputs we feed into the train and validation model at once\n",
        "train_batch = 32\n",
        "valid_batch = 32\n",
        "\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "APMXoM-b81B4",
        "colab": {}
      },
      "source": [
        "# then we need to import the libraries we need\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5zOBRz6rvwfh",
        "colab": {}
      },
      "source": [
        "class YelpDataset(Dataset):\n",
        "\n",
        "  # here we want to  create a customized dataset--YelpDataset--which could take a raw text as input\n",
        "  # and encode it in BERT's way with a tokenizer. \n",
        "  # The tokenized input will be then fed into a BERT Model in the NN, which we will create later\n",
        "\n",
        "  # __init__ defines some necessary attributes for any instance created\n",
        "  # like: the dataset with raw text reviews, what tokenizer we want to use for encoding, \n",
        "  # the max length of sentence we need to pad or trancate\n",
        "  def __init__(self, dataset, tokenizer, max_len):\n",
        "    self.tokenizer = tokenizer\n",
        "    self.data = dataset\n",
        "    self.text = dataset.text\n",
        "    self.label = dataset.label\n",
        "    self.max_len = max_len\n",
        "  \n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.text)\n",
        "\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    # __getitem__ take index as input, \n",
        "    # in general/without customizatin, it returns the sample with the index in the dataset\n",
        "    # further we could customize its functionality, letting it to apply some operations on the \n",
        "    # index-specified sample before return a value for us\n",
        "    # here we use index to locate a specific review text we want to pre-process\n",
        "    # text = str(self.text[index])\n",
        "    # text = \" \".join(text.split())\n",
        "    text = self.text.iloc[index]\n",
        "\n",
        "    # then, we put the text into a BERT encode_plus\n",
        "    # important debug tips: \n",
        "    # for encode_plus, to keep all the raw inputs in the same lenght\n",
        "    # we need to specify BOTH padding and trancation in addition to max_length\n",
        "    # the former for short sentences and the latter for long ones\n",
        "    # failing to do either one will result in uneven lengths of encoded inputs,\n",
        "    # which will create troubles for your dataloader in the nn training sessions\n",
        "    outputs = self.tokenizer.encode_plus(\n",
        "        text,\n",
        "        max_length = self.max_len,\n",
        "        padding = \"max_length\",\n",
        "        truncation = \"longest_first\",\n",
        "        # note that in some versions of transformer in you local machine, the code is \n",
        "        # pad_to_max_length = True,\n",
        "        # truncation_strategy = 'longest_first',\n",
        "        # we might need to change the argument name a little to fit different version of transformers\n",
        "        add_special_tokens = True,\n",
        "        return_tensors = 'pt'\n",
        "    )\n",
        "    # recall the BERT Tokenizer session, it takes raw text as input\n",
        "    # and return input_ids, attention_mask\n",
        "    input_ids = outputs['input_ids']\n",
        "    attention_mask = outputs['attention_mask']\n",
        "    # we then store those values and put them together with the label info in the sample\n",
        "    # as the return of the __getitem__ method\n",
        "    return {\n",
        "        'input_ids': torch.tensor(input_ids, dtype = torch.long),\n",
        "        'attention_mask': torch.tensor(attention_mask, dtype = torch.long),\n",
        "        'label': torch.tensor(self.label.iloc[index], dtype = torch.float) \n",
        "    }\n",
        "\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tZLP1R7vBuKL",
        "colab": {}
      },
      "source": [
        "# split the train and validate dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_raw, valid_raw = train_test_split(train_review, test_size = 0.1)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eRqVwGM5v2_d",
        "colab": {}
      },
      "source": [
        "# create instances of the YelpDataset for raw trianing and validate datasets\n",
        "# recall that tokenizer has be defined by: tokenizer = BertTokenizer.from_pretrained('bert-base-uncased') in the BERT tokenizer session\n",
        "train_processed = YelpDataset(train_raw, tokenizer, max_length)\n",
        "valid_processed = YelpDataset(valid_raw, tokenizer, max_length)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eEl2Jkdksm4i",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "abe0d007-f5b4-46b1-e451-dffd6f92965c"
      },
      "source": [
        "# check the attributes and method of train_processed\n",
        "train_processed.__len__()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1494"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "s7HaY0bQCTXw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "outputId": "d77705b3-0747-4028-c349-6c7bf695acf2"
      },
      "source": [
        "# test the customized Dataset instance\n",
        "print(train_processed.__getitem__(10))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'input_ids': tensor([[  101,  2023,  3319,  3475,  1005,  1056,  2005,  2436, 19342,  2993,\n",
            "          1010,  2021,  2738,  2005,  1996,  2118,  1018, 12541,  3834,  3145,\n",
            "          4003,  2544,  1010,  2029,  5942,  3076, 27354,  1012,  1026,  7987,\n",
            "          1013,  1028,  1026,  7987,  1013,  1028,  1045,  2572,  1037,  3076,\n",
            "          2040,  2038,  2109,  3025,  3076,  4617,  1997,  7513,  2436,  1012,\n",
            "          3568,  1010,  1045,  2106,  2025,  5987,  2151,  3314,  2007,  9398,\n",
            "          5844,  2023,  4031,  2043,  1045,  3641,  2009,  1025,  2174,  1010,\n",
            "          1045,  7714,  2179,  1996,  3076, 27354,  2832,  2061, 25198,  1010,\n",
            "          1045,  3030,  2667,  2000, 16500,  2436, 19342,  1998,  2074,  2318,\n",
            "          9167,  2075,  8224,  9986,  2015,  2046,  2773,  4289,  1998,  3810,\n",
            "          1999,  2026, 14799,  2008,  2126,  1012,  1026,  7987,  1013,  1028,\n",
            "          1026,  7987,  1013,  1028,  2144,  7513,  2003, 19575,  2075,  2023,\n",
            "          4031,  2005,  2216,  1999,  2082,  1010,  1045,   102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1]]), 'label': tensor(0.)}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:59: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hvnlzcFRRcxw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "1d61986d-6291-46d7-924d-7ae54b060637"
      },
      "source": [
        "# see the dimension of the pre-processed data\n",
        "print(train_processed.__getitem__(10)['input_ids'].shape)\n",
        "# we can use the squeeze() method to remove the axis of \"1\", a method we will use later\n",
        "print(train_processed.__getitem__(10)['input_ids'].squeeze().shape)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 128])\n",
            "torch.Size([128])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:59: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "k4T7kvxJEpZX",
        "colab": {}
      },
      "source": [
        "# important, run it again to create a new dataset loader for every NN model you train\n",
        "# lastly, set up the dataloader that serves as a pipeline feeding pre-processed data into the neural network\n",
        "train_sampler = RandomSampler(train_processed)\n",
        "train_loader = DataLoader(train_processed, batch_size = train_batch, num_workers = 0)\n",
        "valid_sampler = SequentialSampler(valid_processed)\n",
        "valid_loader = DataLoader(valid_processed, batch_size = valid_batch, num_workers = 0)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Gl3urqqxHeH9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "ada7de9b-1004-4042-b957-563b19bafecb"
      },
      "source": [
        "# exploer the attributes of dataloder\n",
        "# length of dataloader = len(dataset)/batch size\n",
        "print(len(train_loader))\n",
        "print(len(valid_loader))\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "47\n",
            "6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B4yLzjne6Tm6",
        "colab_type": "text"
      },
      "source": [
        "# Define a Customized Neural Network with the First Hidden Layer as NLP Encoding Layer\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hLuI0Q3ZF2C2"
      },
      "source": [
        "Up to now, we have defined the customized Dataset class that preprocess the raw input, encoding them into input_ids and attention_mask that BERT model needs. We also set up the Dataloader that feed the pre-processed data into the Neural Network we are creating now. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oGetmmKNafv5",
        "colab": {}
      },
      "source": [
        "# import the functions we need use in the Netwrok Model\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ld8Oqz5Jv43c",
        "colab": {}
      },
      "source": [
        "# the neural network we create is a class called  YelpBERT, which inherits\n",
        "# the attributes and structures of the torch.nn.Module\n",
        "\n",
        "# the __init__ functino defines the necessary hidden layers of the NN\n",
        "# and the forward function set up the computation graph: the real calculation procedures of the NN\n",
        "# see the class session 7's slides and recording for details \n",
        "\n",
        "class YelpBERT(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super(YelpBERT, self).__init__()\n",
        "    # recall that, we have defined model as: model = BertModel.from_pretrained('bert-base-uncased')\n",
        "    # see BERT Model's input and output: https://huggingface.co/transformers/model_doc/bert.html#bertmodel\n",
        "    self.l1 = model\n",
        "\n",
        "    # with this layer a percentage of all neurons will be randomly turned-off to prevent overfitting\n",
        "    # since our training dataset might be small, we really cannot afford a large neural network\n",
        "    # the output of the BERT layer is a vector of 768 elements, if fully connected to next linear layer\n",
        "    # then the current layer would have 768 neurons, too much! \n",
        "    # using dropout mechanism, we can randomly turn off a percentage of the neuraon in the training process\n",
        "    # literally reduced the number of neuron in the layer\n",
        "    self.l2 = torch.nn.Dropout(0.3) \n",
        "\n",
        "    # if you want to have multiple fully connected linear layer, use this\n",
        "    # self.l2 = torch.nn.Linear(768, 10)\n",
        "    # but again, if your training dataset is not very large, we may only offard one linear layer\n",
        "    \n",
        "    # last layer\n",
        "    self.l3 = torch.nn.Linear(768, 1)\n",
        "\n",
        "\n",
        "  \n",
        "  def forward(self, input_ids, attention_mask):\n",
        "    # first layer\n",
        "    # the first layer utilize the BERT model (call \"model\" in __init__) to transfer the input_ids into\n",
        "    # contextualized word embeddings --numerical vectors\n",
        "    # we can customize the output of this layer such as using the [CLS] token or the mean of all input tokens\n",
        "   \n",
        "    # if you want to use the BERT output of the last self-attention layer, use this:\n",
        "    last, pooler = self.l1(input_ids = input_ids, attention_mask = attention_mask)\n",
        "   \n",
        "    # if you want to use BERT output from OTHER self-attention layers,use this:\n",
        "    # (note that BERT base model has 12 hidden self-attention layers), \n",
        "    # last, pooler, all = self.l1(input_ids = input_ids, attention_mask = attention_mask, output_hidden_states = True)\n",
        "    \n",
        "    # second layer\n",
        "    # here we could use the mean value of tokens of all raw inputs as the embedding of the whole input text\n",
        "    # and feed it into the second layer, use this: \n",
        "    # output from last BERT self-attention layer:\n",
        "    # initial index \"0\" for mean value of [cls] token and all non-padded tokens\n",
        "    # initial index \"1\" for mean value of all non-padded tokens only\n",
        "    output = last[:, 0 : attention_mask.sum(), :].mean(dim = 1)\n",
        "    # BERT output from other hidden self-attention layer:\n",
        "    # output = all[11][:, 0 : attention_mask.sum(), :].mean(dim = 1)\n",
        "    \n",
        "    # or use the [CLS] token of last layer\n",
        "    # output = last[:, 0, :]\n",
        "\n",
        "    # output from BERT model now be fed into a relu activation funcation adn\n",
        "    # the second layer of the Neural Network\n",
        "    output = F.relu(output.squeeze())\n",
        "    output = F.relu(self.l2(output))\n",
        "\n",
        "    # why squeeze(): to make the dimension of input-output across layers consistent\n",
        "    # e.g., the output of layer 1--self.l1, is in the shape of (1, 768),\n",
        "    # we use .squeeze() to make it in a shape of (768) only, \n",
        "    # because the later layer--l2 adn l2--take (768) as input dimension not (1, 768)\n",
        "\n",
        "    # third layer\n",
        "    output = self.l3(output)\n",
        "\n",
        "    # last sigmoid layer to furhter transfer the single scalar of l3 into a probability\n",
        "    return torch.sigmoid(output)\n",
        "    # note that we can also customize the layers after the 1st one, \n",
        "    # making more layers (i.e., a deeper NN) and see if it perform betters "
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "m8yf6W_iSdCJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "574cf9c5-7c12-4fe0-98ba-f91961add5a2"
      },
      "source": [
        "# test the model step-by-step\n",
        "# compare the output dimension to your expectation\n",
        "# https://huggingface.co/transformers/model_doc/bert.html#bertmodel\n",
        "# testing each layer in the NN is very important\n",
        "# we should pay close attention the the dimensions of the inputs and outputs of each layer \n",
        "# use .squeeze() to remove uncessary axis whose length is 1 to make the dimensions consistent. like \"output = pooler.squeeze()\" in the NN above\n",
        "l1 = model\n",
        "l1.to(device)\n",
        "input_ids = train_processed.__getitem__(10)['input_ids'].to(device)\n",
        "attention_mask = train_processed.__getitem__(10)['attention_mask'].to(device)\n",
        "last, pooler = l1(input_ids = input_ids, attention_mask = attention_mask)\n",
        "print(last.shape)\n",
        "print(last.squeeze().shape)\n",
        "print(pooler.shape)\n",
        "print(pooler.squeeze().shape)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 128, 768])\n",
            "torch.Size([128, 768])\n",
            "torch.Size([1, 768])\n",
            "torch.Size([768])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:59: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zuR1CGxHpNDt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "b39ed468-1b39-4c13-99a0-691a2914c313"
      },
      "source": [
        "# similarly, test if the dimensions of input and output \n",
        "output = last[:, 1 : attention_mask.sum(), :].mean(dim = 1)\n",
        "output = output.squeeze()\n",
        "output.shape\n",
        "l2 = torch.nn.Dropout(0.5)   \n",
        "l2.to(device)\n",
        "l3 = torch.nn.Linear(768, 1)\n",
        "l3.to(device)\n",
        "output.to(device)\n",
        "l3(l2(torch.tensor(output)))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.1632], device='cuda:0', grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NaSSY_mynUVw"
      },
      "source": [
        "# Create a BERT + NN Model as an Instance of the Customized Model Classs Defined Above and Setup the Loss Function and Optimizer\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aFDDnyD6wlD4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "282d728a-f767-449a-e59b-cc52debbc305"
      },
      "source": [
        "# create an instance of the YelpBERT model\n",
        "# remember to recreat a instance of the Model Class after you modified the YelpBERT class\n",
        "model_yelp = YelpBERT()\n",
        "model_yelp.to(device)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "YelpBERT(\n",
              "  (l1): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (l2): Dropout(p=0.3, inplace=False)\n",
              "  (l3): Linear(in_features=768, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2BnImCNBLxG_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "8f024a69-e592-4047-8461-575e77cb9e2c"
      },
      "source": [
        "# test the model_yelp\n",
        "# recall that the train_processed is a special class that could pre-process the raw input words into input_ids\n",
        "# and attentino_mask using its method __getitem__ method\n",
        "# we then use this method to get the input_ids and attention_mask that we need to feed in the YelpBERT() model\n",
        "\n",
        "test_output = model_yelp(input_ids, attention_mask)\n",
        "print(len(test_output))\n",
        "print(test_output)\n",
        "# note that the output is a scalar, becasue ofthe last hidden layer in the NN, self.l3 = torch.nn.Linear(768, 1)\n",
        "# the scalar then can be put into a softmax for prediction \n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "tensor([0.4804], device='cuda:0', grad_fn=<SigmoidBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7QmZRjGkPVAI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "bc70b359-ee1f-4b9d-9174-b0438a75227d"
      },
      "source": [
        "print(input_ids.shape)\n",
        "print(attention_mask.shape)\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 128])\n",
            "torch.Size([1, 128])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Nrrzk6ukepKO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "380e64a2-d679-4b3d-9a46-d07e9a8d11f5"
      },
      "source": [
        "# check out the model parameters\n",
        "# note that the first BERT layer, the word embeddings are in the shape of (30522, 768)\n",
        "# and we can tell that the first 12 layers of our model are normal BERT layers, \n",
        "# the last two are what we customized-- a dropout layer and the linear layer\n",
        "model_yelp.parameters"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method Module.parameters of YelpBERT(\n",
              "  (l1): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (l2): Dropout(p=0.3, inplace=False)\n",
              "  (l3): Linear(in_features=768, out_features=1, bias=True)\n",
              ")>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4enOR93aXnCG"
      },
      "source": [
        "Up to now, we have the Dataset (pre-process/encode the raw text inputs, making them into input_ids that BERT model takes as input), the Dataloader (feed the processed data into the NN in batchs), the neural network (with the first layer as a BERT model, the transfer the encoded input_ids into word embeddings, and later layers just work on those embeddings/numerical vectors as normal neural network). \n",
        "\n",
        "And finally, we could set up our training loops"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "iZpo8C-zc-B3"
      },
      "source": [
        "First we start with: the loss function (e.g., crossentropy loss or mean squared error loss) and the optimize schedule (some thing about learning rate, adaptive learning rate, see class 7)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7TRC6Dbzc8oZ",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Q4QtC037dzxO",
        "colab": {}
      },
      "source": [
        "# criterion is the loss function we use\n",
        "# here we use Binary CrossEntropy Loss, you can try others see the performance difference\n",
        "# https://pytorch.org/docs/master/generated/torch.nn.BCELoss.html\n",
        "criterion = nn.BCELoss()\n",
        "# note that loss function in pytorch framework usually take the pair of (prediction, ground_truth) as input\n",
        "# and give the loss value as output"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "d0MvxRbleYiO",
        "colab": {}
      },
      "source": [
        "# optimizer is our optimize strategy, here we use stachastic gradient descending as the approch \n",
        "# to update our model parameters. \n",
        "# tips: previously I trained multiple models but with learning rate = 1e-05, 3e-05, \n",
        "# after 4 epochs the model performance almost doesn't change\n",
        "# thus now I use 10e-05, it seems the performance improves faster\n",
        "learning_rate = 10e-05\n",
        "# SGD is a common optimizer, but let's use Adam here, AdamW is a optimizer developed by Huggingface using Adam's mechanism\n",
        "# optimizer = optim.SGD(model_yelp.parameters(), lr = learning_rate, momentum = 0.9)\n",
        "# http://deeplearning.stanford.edu/tutorial/supervised/OptimizationStochasticGradientDescent/\n",
        "# you can try out other optimization method and see performance difference"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "njBahjNyjByc",
        "colab": {}
      },
      "source": [
        "# set the epoch\n",
        "epochs = 5\n",
        "# epochs means how many rounds each training sample will be fed into the NN.\n",
        "# next, we need to supply our model \"model_yelp\" to the GPU, so it can be run on GPU\n",
        "# model_yelp.to(device)\n",
        "# since the GPU has a lot of cores, it takes some time to supply to model to the GPU\n"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FEUQBFhMhsHt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# try another optimizer\n",
        "from transformers import AdamW\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "optimizer = AdamW(model_yelp.parameters(),lr = learning_rate,eps = 1e-8)\n",
        "                  \n",
        "total_steps = len(train_loader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler that update the learning rate gradully, this scheduler is with AdamW\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps = 0, num_training_steps = total_steps)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WUy2sgBBgz50",
        "colab": {}
      },
      "source": [
        "# lastly, let's define a helper function we can use for calculating the prediction accuracy\n",
        "import numpy as np\n",
        "# the idea of the funtion is that a vector of predicted probablity of being good review, \n",
        "# which is the output of the sigmoid/last layer of the neural network, is compared with the true label\n",
        "# is the predicted probability >= 0.5, we assign 1, otherwise we assign 0, we use np.around() achieve this\n",
        "def pred_accuracy (prediction, label):\n",
        "  pred_flat = np.around(prediction).flatten()\n",
        "  label_flat = label.flatten()\n",
        "  return np.sum(pred_flat == label_flat) / len(label_flat)\n"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U2WFSgu6_1VL",
        "colab_type": "text"
      },
      "source": [
        "# Train the BERT + NN Model and Evaluate the Performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DFPc5CRqiESW",
        "colab": {}
      },
      "source": [
        "# set the random set the same, making the results reproducible\n",
        "import random\n",
        "seed_val = 45\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_SCqZW_Dn6x5"
      },
      "source": [
        "OK, finally, we strat to train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CpYKGk-NeCUZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d2313ba9-d247-461a-8dac-6217f41dbd29"
      },
      "source": [
        "# create an instance of the YelpBERT model\n",
        "model_yelp = YelpBERT()\n",
        "model_yelp.to(device)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "YelpBERT(\n",
              "  (l1): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (l2): Dropout(p=0.3, inplace=False)\n",
              "  (l3): Linear(in_features=768, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "a417dCiz3VWS",
        "colab": {}
      },
      "source": [
        "# set up the directory for storing the trained model\n",
        "import os\n",
        "# save to Google Drive\n",
        "dir = \"/content/drive/My Drive\"\n",
        "# save to local file\n",
        "# dir = \"E://OneDrive - lmu.edu//Python Projects//BERT and ML\"\n"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "H0gMiqrmix5g",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 683
        },
        "outputId": "802a3812-4e3a-466d-a46d-cda985449a8f"
      },
      "source": [
        "# Very Important: Each Time When You Train a Neural Network Again, \n",
        "# Plase recreate the nural network, the dataloader, and the optimizer and its scheduler.\n",
        "\n",
        "\n",
        "# train the model \n",
        "# store the total loss and accuracy values of each epoch\n",
        "training_stats = []\n",
        "\n",
        "# the epoch loop, number of rounds specified by epochs\n",
        "for epoch_i in range(0, epochs):\n",
        "  print('======== Epoch {:} / {:} =========='.format(epoch_i + 1, epochs))\n",
        "  # zero the values of total loss and accuracy of the epoch\n",
        "  total_loss = 0\n",
        "  total_accuracy = 0\n",
        "  # in the training stage, set the model into train mode\n",
        "  model_yelp.train()\n",
        "\n",
        "  # the training step loop\n",
        "  # recall that train_loader feed data into the NN in batchs to save memory and improve efficiency\n",
        "  # then the # of total steps is about (# of samples/batch size)\n",
        "  print(\"training\")\n",
        "  for step, batch in enumerate(train_loader, 0):\n",
        "    # feed the data into GPU using .to(device) method\n",
        "    # note that the input_ids for one raw input is in the shape of (1, max_length)\n",
        "    # after be processed into batch, the input_ids become (batch_size, 1, max_length)\n",
        "    # however, BERT only takes input_ids in the shape of (batch_size, max_length),\n",
        "    # (see here: https://huggingface.co/transformers/model_doc/bert.html#bertmodel)\n",
        "    # so we need to do \"batch['input_ids'].squeeze()\" inestead of \"batch['input_ids']\"\n",
        "    # to remove the unnecessy axis of \"1\". \n",
        "    # same operation for attention_mask\n",
        "    input_ids = batch['input_ids'].squeeze().to(device, dtype = torch.long)\n",
        "    attention_mask = batch['attention_mask'].squeeze().to(device, dtype = torch.long)\n",
        "    label = batch['label'].to(device, dtype = torch.float)\n",
        "\n",
        "    # at each step, before the NN does the feed forward, let's set the gradient to 0\n",
        "    # as pytorch nn.Module automatically cumulates gradient from previous rounds\n",
        "    # this is good for RNN training, but not necessy for us here. Thus, we turn it off.   \n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    # for each raw input, the feed forward calculation give us two scalar, \n",
        "    # representing the score/probability of the sample being 0/bad review class or 1/good review class  \n",
        "    # note that since we feed the inputs/raw samples in batch, \n",
        "    # the prediciton should be in the shape of (batch_size, # of classes)\n",
        "    prediction = model_yelp(input_ids, attention_mask)\n",
        "    prediction = prediction.squeeze()\n",
        "\n",
        "    # criterion is defined as a cross entropy loss function\n",
        "    # it takes (prediction, ground truth) as input arugments\n",
        "    # the former should be in the shape of (batch_size, # of classes), \n",
        "    # the latter should be in the sahpe of (batch_szie, 1), \"1\" dimension records the true class id of the input\n",
        "    # https://pytorch.org/docs/master/generated/torch.nn.CrossEntropyLoss.html   \n",
        "    loss = criterion(prediction, label)\n",
        "\n",
        "    # with the loss, we can do back propagation to calculate the gradient\n",
        "    # very easy, just one line of code  \n",
        "    loss.backward()\n",
        "\n",
        "    # with the gradient, we can update the model paramters. \n",
        "    # recall how we define the optimizer in the above cell  \n",
        "    optimizer.step()\n",
        "    \n",
        "    # update the learning rate\n",
        "    scheduler.step()\n",
        "\n",
        "    # to keep tracking on the model performance, we accumulate the total loss in every epoch  \n",
        "    total_loss += loss.item()\n",
        "      \n",
        "    # for every 10 steps, we print out the epoce # and loss\n",
        "    # again, the max_length of raw text input is 256, relatively long than usual, thus it will take longer to train. \n",
        "    if step%10 == 0 and step != 0:\n",
        "      print(f'Epoch:{epoch_i + 1}, Total_Loss:{total_loss}, Average_Loss:{total_loss/step}')\n",
        "  \n",
        "  # calcualte and store the average training loss of each batch in the current epoch\n",
        "  avg_train_loss = total_loss / len(train_loader)\n",
        "\n",
        "  \n",
        "\n",
        "  # now let's set up the validation loop, meaning the trained model above will be used to evaluate the sample in validation dataset\n",
        "  # note that this validation loop is in the same \"indent\" level as the training loop, and they both under the epoches loop\n",
        "  print(\"validating\")\n",
        "  # set the model now in the evaluation mode\n",
        "  model_yelp.eval()\n",
        "  # zero the values of total loss and accuracy\n",
        "  total_loss = 0\n",
        "  #total_accuracy = 0\n",
        "\n",
        "  # validation loop\n",
        "  for step, batch in enumerate(valid_loader, 0):\n",
        "    input_ids = batch['input_ids'].squeeze().to(device, dtype = torch.long)\n",
        "    attention_mask = batch['attention_mask'].squeeze().to(device, dtype = torch.long)\n",
        "    label = batch['label'].to(device, dtype = torch.float)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        prediction = model_yelp(input_ids, attention_mask)\n",
        "        prediction = prediction.squeeze()\n",
        "        loss = criterion(prediction, label)\n",
        "\n",
        "    total_loss += loss.item()\n",
        "\n",
        "    if step%10 == 0 and step != 0:\n",
        "      print(f'Epoch:{epoch_i + 1}, Total_Loss:{total_loss}, Average_Loss:{total_loss/step}')\n",
        "\n",
        "  # calcualte and store the average training loss of each batch in the current epoch\n",
        "  avg_valid_loss = total_loss / len(valid_loader)\n",
        "\n",
        "  training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_valid_loss\n",
        "        }\n",
        "    )\n",
        "  \n",
        "\n",
        "\n",
        "  # lastly, at the end of each epoch, let's save the model for later use\n",
        "  # note that dir is defined before as \"./content/drive/My Drive\"  \n",
        "  #torch.save(model_yelp.state_dict(), os.path.join(dir, 'exper-epoch-{}.pt'.format(epoch_i)))\n",
        "\n",
        "print(\"training complete!\")\n",
        "\n"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "======== Epoch 1 / 5 ==========\n",
            "training\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:59: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch:1, Total_Loss:1.6158906817436218, Average_Loss:0.1615890681743622\n",
            "Epoch:1, Total_Loss:2.877324655652046, Average_Loss:0.1438662327826023\n",
            "Epoch:1, Total_Loss:4.74433321505785, Average_Loss:0.15814444050192833\n",
            "Epoch:1, Total_Loss:6.157756082713604, Average_Loss:0.1539439020678401\n",
            "validating\n",
            "======== Epoch 2 / 5 ==========\n",
            "training\n",
            "Epoch:2, Total_Loss:0.9922568667680025, Average_Loss:0.09922568667680025\n",
            "Epoch:2, Total_Loss:1.8009488116949797, Average_Loss:0.09004744058474898\n",
            "Epoch:2, Total_Loss:2.7491192910820246, Average_Loss:0.09163730970273415\n",
            "Epoch:2, Total_Loss:3.4951635729521513, Average_Loss:0.08737908932380378\n",
            "validating\n",
            "======== Epoch 3 / 5 ==========\n",
            "training\n",
            "Epoch:3, Total_Loss:0.9229252673685551, Average_Loss:0.0922925267368555\n",
            "Epoch:3, Total_Loss:1.6444316823035479, Average_Loss:0.0822215841151774\n",
            "Epoch:3, Total_Loss:2.488222012296319, Average_Loss:0.08294073374321063\n",
            "Epoch:3, Total_Loss:3.0946149323135614, Average_Loss:0.07736537330783903\n",
            "validating\n",
            "======== Epoch 4 / 5 ==========\n",
            "training\n",
            "Epoch:4, Total_Loss:0.8245174326002598, Average_Loss:0.08245174326002598\n",
            "Epoch:4, Total_Loss:1.3435794292017817, Average_Loss:0.06717897146008908\n",
            "Epoch:4, Total_Loss:1.9512290013954043, Average_Loss:0.06504096671318015\n",
            "Epoch:4, Total_Loss:2.329213217832148, Average_Loss:0.0582303304458037\n",
            "validating\n",
            "======== Epoch 5 / 5 ==========\n",
            "training\n",
            "Epoch:5, Total_Loss:0.7919339099898934, Average_Loss:0.07919339099898934\n",
            "Epoch:5, Total_Loss:1.2729999870061874, Average_Loss:0.06364999935030938\n",
            "Epoch:5, Total_Loss:1.8054118128493428, Average_Loss:0.06018039376164476\n",
            "Epoch:5, Total_Loss:2.1290292078629136, Average_Loss:0.05322573019657284\n",
            "validating\n",
            "training complete!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "B5soA_VPd2Ry",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 498
        },
        "outputId": "4655435a-3a47-434a-db67-3227a50c7485"
      },
      "source": [
        "# plot the train statistics stored in training_stats\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "sns.set(style = \"darkgrid\")\n",
        "\n",
        "sns.set(font_scale = 1.5)\n",
        "plt.rcParams['figure.figsize'] = [12, 6]\n",
        "\n",
        "df_stats = pd.DataFrame(data = training_stats)\n",
        "\n",
        "# Use the 'epoch' as the row index.\n",
        "df_stats = df_stats.set_index('epoch')\n",
        "\n",
        "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
        "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
        "\n",
        "plt.title(\"Training loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fc6c6998898>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9zXX5Pdvw9I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# make sure to save the model performance statistics and the associated model configuration. \n",
        "# that is save the df_stats to csv file with a file name, say experiment 1\n",
        "df_stats.to_csv(os.path.join(dir, 'label_experiment_3.csv'))\n",
        "# save the key hyper-parameters of this training experiment, say experiment 1\n",
        "label_experiment_3_config = {\n",
        "    \"epochs\": epochs,\n",
        "    \"train_batch_size\" : train_batch,\n",
        "    \"valid_batch_size\" : valid_batch,\n",
        "    \"initial_learning_rate\": learning_rate,\n",
        "     \"max_sentence_length\": max_length,\n",
        "     \"loss_fucntion\": criterion,\n",
        "     \"optimizer\": optimizer,\n",
        "     # you need to manually type-in the following info\n",
        "     \"BERT output\": \"mean value of [cls] embeddings of non-padded token from the second to the last layer\",\n",
        "     \"activation function\": \"relu\",\n",
        "     \"dropout rate of BERT output\": model_yelp.l2,\n",
        "     \"# of fully connected linear layer\": 1,\n",
        "     \"dataset\": \"Yelp Review Balanced\",\n",
        "     \"comment\": \"sees not as good as the outputs of last layer\"\n",
        "}\n"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odvnYYhghsH5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# save the experiment configurate assocaited with this experiment\n",
        "# note that if you click the file icon (the third vertical one on the far left)\n",
        "# you will see the save files, double click on them, you can see them.\n",
        "import csv\n",
        "with open(os.path.join(dir, 'label_experiment_3_config.csv'), 'w') as csv_file:  \n",
        "    writer = csv.writer(csv_file)\n",
        "    for key, value in label_experiment_3_config.items():\n",
        "       writer.writerow([key, value])"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WinIsU6zMpWt",
        "colab_type": "text"
      },
      "source": [
        "# Evaluate the Model Performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "p9MQQ6yU9kLo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "7a6ed901-f7c9-49e5-f93a-d13c38964acb"
      },
      "source": [
        "# apply the trained model to the validation dataset\n",
        "# get the model predictions and compare the comparisons to the true labels\n",
        "model_yelp.eval()\n",
        "predictions, labels = [], []\n",
        "for step, batch in enumerate(valid_loader):\n",
        "  input_ids = batch['input_ids'].squeeze().to(device, dtype = torch.long)\n",
        "  attention_mask = batch['attention_mask'].squeeze().to(device, dtype = torch.long)\n",
        "  label = batch['label'].to('cpu').numpy()\n",
        "  \n",
        "  with torch.no_grad():\n",
        "    prediction = model_yelp(input_ids, attention_mask)\n",
        "\n",
        "  prediction = prediction.detach().cpu().numpy()\n",
        "  predictions.append(prediction)\n",
        "  labels.append(label)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:59: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tA38tbL6Qkv7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e817ec26-ff47-406d-df46-c67325ac0331"
      },
      "source": [
        "# call the helper function-- pred_accuacy to compute the prediction accuracy in each batch\n",
        "ac = []\n",
        "for i in range(len(predictions)):\n",
        "  ac_i = pred_accuracy(predictions[i], labels[i])\n",
        "  ac.append(ac_i)\n",
        "ac"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.96875, 1.0, 0.96875, 1.0, 0.90625, 0.8333333333333334]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QaL7PHMQOvjZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        },
        "outputId": "76f3c880-3ff1-469d-8243-70f026b8000c"
      },
      "source": [
        "# transfer the outcomes into np\n",
        "predictions = np.asarray(predictions)\n",
        "labels = np.asarray(labels)\n",
        "predictions[0]\n",
        "# note that now the outcomes are still stored in batches"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.00769942],\n",
              "       [0.00856103],\n",
              "       [0.00736088],\n",
              "       [0.00731411],\n",
              "       [0.00736012],\n",
              "       [0.00846946],\n",
              "       [0.00765256],\n",
              "       [0.0068667 ],\n",
              "       [0.00747262],\n",
              "       [0.01368819],\n",
              "       [0.00724405],\n",
              "       [0.00780635],\n",
              "       [0.00719203],\n",
              "       [0.0077774 ],\n",
              "       [0.00680867],\n",
              "       [0.00686704],\n",
              "       [0.00828413],\n",
              "       [0.941708  ],\n",
              "       [0.00678866],\n",
              "       [0.00693297],\n",
              "       [0.00693977],\n",
              "       [0.00755867],\n",
              "       [0.00726407],\n",
              "       [0.00853795],\n",
              "       [0.00715   ],\n",
              "       [0.00715341],\n",
              "       [0.00919186],\n",
              "       [0.00834908],\n",
              "       [0.00712519],\n",
              "       [0.00788126],\n",
              "       [0.00773134],\n",
              "       [0.00763724]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWiqZYkAhsID",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "183c1f96-9f04-4117-d9e3-fd8efb153b21"
      },
      "source": [
        "# convert predictions stored in the batches into a long vector\n",
        "pred = np.concatenate(predictions, axis=0 )\n",
        "pred = np.concatenate(pred, axis=0 )\n",
        "pred = pred.reshape(len(pred),1)\n",
        "print(pred.shape)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(166, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z5kkRWD0hsIE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "90899435-797b-46b5-b3e1-fbe908b0bd26"
      },
      "source": [
        "# convert the true labels batches into a long vector\n",
        "true_label = np.concatenate(labels, axis=0 )\n",
        "true_label = true_label.reshape(len(true_label), 1)\n",
        "print(true_label.shape)\n",
        "type(true_label)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(166, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXEasNQvhsIF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "e205ac3d-9dad-4e80-c0be-e79072a71a1d"
      },
      "source": [
        "# put the predictions and labels into the same dataset\n",
        "df = np.concatenate([pred, true_label], axis = 1)\n",
        "df = pd.DataFrame(data=df, columns=[\"preds\", \"labels\"])\n",
        "df"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>preds</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.007699</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.008561</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.007361</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.007314</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.007360</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>161</th>\n",
              "      <td>0.007524</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>162</th>\n",
              "      <td>0.010498</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>163</th>\n",
              "      <td>0.941007</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>164</th>\n",
              "      <td>0.184911</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>165</th>\n",
              "      <td>0.007816</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>166 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        preds  labels\n",
              "0    0.007699     0.0\n",
              "1    0.008561     0.0\n",
              "2    0.007361     0.0\n",
              "3    0.007314     0.0\n",
              "4    0.007360     0.0\n",
              "..        ...     ...\n",
              "161  0.007524     0.0\n",
              "162  0.010498     0.0\n",
              "163  0.941007     1.0\n",
              "164  0.184911     1.0\n",
              "165  0.007816     0.0\n",
              "\n",
              "[166 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pjqBh76onyd-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "546405e3-c166-4c64-b9a4-764ec6b93fb5"
      },
      "source": [
        "# see the total prediction accuracy\n",
        "sum((df[\"preds\"]>=0.5) == df[\"labels\"])"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "160"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9r7T9I_yhsIJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "outputId": "9d4e008c-a8a7-449f-f745-a117efe8911e"
      },
      "source": [
        "# find the index of the review that has the lowest predicted probabilty(of being a positive review) in true_label == 1 group. \n",
        "df.loc[df.loc[df['labels'] == 1, :].idxmin()]"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>preds</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>135</th>\n",
              "      <td>0.007357</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0.008284</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        preds  labels\n",
              "135  0.007357     1.0\n",
              "16   0.008284     1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VurVKLthsIK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3fff26f9-afa2-4c4f-93ad-a3ff16f02ce3"
      },
      "source": [
        "# see that review\n",
        "valid_raw.iloc[19,0]\n"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Product was top quality at a great price. I hooked them up and they work great. Cannot go wrong with these cables.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9PDrrPNhsIN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "outputId": "49c50b32-9674-494f-8514-02ab2815d367"
      },
      "source": [
        "# alternatively, for all the reviews that have true_label == 1, \n",
        "# let's sort their predicted probabilities\n",
        "df.loc[df['labels'] == 1, :].sort_values('preds')"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>preds</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>135</th>\n",
              "      <td>0.007357</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>150</th>\n",
              "      <td>0.008234</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0.008284</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>164</th>\n",
              "      <td>0.184911</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>0.786822</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>130</th>\n",
              "      <td>0.819385</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>0.927735</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>152</th>\n",
              "      <td>0.928506</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>83</th>\n",
              "      <td>0.934443</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>157</th>\n",
              "      <td>0.935312</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>0.938290</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>0.939520</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75</th>\n",
              "      <td>0.939592</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>0.940656</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>110</th>\n",
              "      <td>0.940819</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>163</th>\n",
              "      <td>0.941007</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0.941708</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>0.941892</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        preds  labels\n",
              "135  0.007357     1.0\n",
              "150  0.008234     1.0\n",
              "16   0.008284     1.0\n",
              "164  0.184911     1.0\n",
              "147  0.786822     1.0\n",
              "130  0.819385     1.0\n",
              "47   0.927735     1.0\n",
              "152  0.928506     1.0\n",
              "83   0.934443     1.0\n",
              "157  0.935312     1.0\n",
              "51   0.938290     1.0\n",
              "48   0.939520     1.0\n",
              "75   0.939592     1.0\n",
              "60   0.940656     1.0\n",
              "110  0.940819     1.0\n",
              "163  0.941007     1.0\n",
              "17   0.941708     1.0\n",
              "97   0.941892     1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1FZooOSNTGDl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "7942e3cb-3035-4890-bea0-c94e605d33c1"
      },
      "source": [
        "df[df['labels']==1].preds.sort_values()[0:20]"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "135    0.007357\n",
              "150    0.008234\n",
              "16     0.008284\n",
              "164    0.184911\n",
              "147    0.786822\n",
              "130    0.819385\n",
              "47     0.927735\n",
              "152    0.928506\n",
              "83     0.934443\n",
              "157    0.935312\n",
              "51     0.938290\n",
              "48     0.939520\n",
              "75     0.939592\n",
              "60     0.940656\n",
              "110    0.940819\n",
              "163    0.941007\n",
              "17     0.941708\n",
              "97     0.941892\n",
              "Name: preds, dtype: float32"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wslamubJhsIQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "outputId": "92b45b7a-5a35-4b82-b323-6f40568399bd"
      },
      "source": [
        "# see the reviews\n",
        "valid_raw.iloc[23,0]"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"I'd give this 0 starts if I could. I installed this on my computer and when I tried running it, it kept saying put in the code to access it. I already did that. I contacted Adobe and spent 35 minutes with them only to have them say uninstall it and then reinstall it. Did that same results. I'd like my money back. DON'T waste your money on this. We have purchased several of the previous versions and have been really pleased, but this one really isn't worth the time and energy. Adobe support isn't good either. They ship it over to India and it's difficult to understand the directions they give you. Update: After getting a message to tell Adobe what they had to do in order to correct the problem, after explaining to them I had not a total grasp as the &#34;technical support&#34; did it. Brett then stated I was too vague and that was it. My wife has since then tried use the program and it's not as user friendly as previous versions---can't do as much with putting things side by side to organize files as with previous versions. I wish I didn't waste my money on this product---BUYER BEWARE!!!!! Customer service is horrible as is the product. I wouldn't recommend this version to anyone!!! Go with a previous version if you want adobe---we have 8 and it works a lot better\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "otzAxck1hsIR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "67a65eb2-089b-4bd2-8b99-2fdfe9bbedc6"
      },
      "source": [
        "# on the other way around, for all the reviews whose label == 0, \n",
        "# let's sort their predicted probablities in descending order\n",
        "df[df['labels'] == 0].sort_values('preds', ascending = False)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>preds</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>67</th>\n",
              "      <td>0.924687</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>138</th>\n",
              "      <td>0.918648</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>154</th>\n",
              "      <td>0.384436</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>124</th>\n",
              "      <td>0.170186</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102</th>\n",
              "      <td>0.155304</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>0.006809</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0.006809</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>120</th>\n",
              "      <td>0.006792</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0.006789</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>0.006776</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>148 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        preds  labels\n",
              "67   0.924687     0.0\n",
              "138  0.918648     0.0\n",
              "154  0.384436     0.0\n",
              "124  0.170186     0.0\n",
              "102  0.155304     0.0\n",
              "..        ...     ...\n",
              "43   0.006809     0.0\n",
              "14   0.006809     0.0\n",
              "120  0.006792     0.0\n",
              "18   0.006789     0.0\n",
              "50   0.006776     0.0\n",
              "\n",
              "[148 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjDkJr_VhsIU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8d6cce56-658f-44a0-e333-afa7d099e345"
      },
      "source": [
        "# see the reviews\n",
        "# after learning some examples, it seems that our model will give a high score as long as the food is good\n",
        "# even though the service is not. \n",
        "valid_raw.iloc[26,0]"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'very cute, soft , consistent with the size , I really like'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    }
  ]
}